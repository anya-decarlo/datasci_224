{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e0c2ad-c4c1-42da-8181-6d76bec34e0e",
   "metadata": {
    "id": "43e0c2ad-c4c1-42da-8181-6d76bec34e0e"
   },
   "source": [
    "Welcome to Lab 3! The goal of this lab is to see if you can build on your knowledge about the Lasso and Ridge to understand more sophisticated penalization methods. In addition, we'll see how to run cross-validation in `sklearn` and how to implement bootstrap on our own.\n",
    "\n",
    "**Elastic Net**\n",
    "\n",
    "The Elastic net is a popular penalization method for linear regression that combines the L1 and L2 penalties.\n",
    "\n",
    "Useful references:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "* https://en.wikipedia.org/wiki/Elastic_net_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c621b",
   "metadata": {
    "id": "e81c621b"
   },
   "source": [
    "Q1: What is the optimization problem for logistic regression with an elastic net penalty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r8cZuKfW3Mzg",
   "metadata": {
    "id": "r8cZuKfW3Mzg"
   },
   "source": [
    "$\\min_w 1 /n \\sum_{i=1}^n \\left(y_i \\log \\hat{p}_{w}(x) + (1 - y_i) \\log (1 - \\hat{p}_{w}(x)) \\right)+  \\lambda \\alpha \\|w\\|_1 + 0.5 * \\lambda (1 - \\alpha) \\|w\\|^2_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fb067",
   "metadata": {
    "id": "761fb067"
   },
   "source": [
    "Q2: What are the advantages to fitting an elastic net model as opposed to a Lasso or ridge-penalized model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pb4OT57q4S40",
   "metadata": {
    "id": "pb4OT57q4S40"
   },
   "source": [
    "Lasso regression tends to fit very sparse solutions, sometimes overly sparse. In particular, if there is a group of features that are highly correlated, the lasso tends to just pick one of them at random. On the other hand, elastic net tends to select the entire group of features in this situation, acknowledging the fact that it does not know which feature is the right one.\n",
    "\n",
    "More generally, the set of models considered by elastic net is a superset of the Lasso, as the Lasso is a special case of the elastic net with $\\alpha = 0$. Therefore there is likely some set of hyperparameters for the elastic net that outperforms the Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0115e2",
   "metadata": {
    "id": "ac0115e2"
   },
   "source": [
    "Q3: How is the elastic net penalty related to the Lasso and ridge penalties? That is, when is using an elastic net penalty the same as using the Lasso? When is it the same as using the ridge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gk5kHvV95wbC",
   "metadata": {
    "id": "Gk5kHvV95wbC"
   },
   "source": [
    "The Elastic-net penalty is an additive mixture of the Lasso and ridge penalties. The hyperparameter $\\alpha$ the proportion of the lasso penalty and $1 - \\alpha$ defines the proportion of the ridge penalty. When $\\alpha = 0$, the objective function reduces to that of the Lasso. When $\\alpha = 1$, the objective function reduces to that of ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a7420",
   "metadata": {
    "id": "6d3a7420"
   },
   "source": [
    "Q4: What are the hyperparameters for an elastic net model? How would you tune them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QL4y76F753FX",
   "metadata": {
    "id": "QL4y76F753FX"
   },
   "source": [
    "The hyperparameters for the elastic net are $\\alpha$ (ratio for the L1 penalty) and $\\lambda$ (overall penalty parameter). We need to test different configurations of the hyperparameters by using a grid search over different values of $\\alpha$ and $\\lambda$. We should search over values of $\\alpha$ ranging from 0 to 1. We should search over positive values of $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cfd00-ec55-45ce-b999-3c86a475d348",
   "metadata": {
    "id": "264cfd00-ec55-45ce-b999-3c86a475d348"
   },
   "source": [
    "Q5: Load the breast cancer dataset and split 50/50 for training and test: https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset .\n",
    "\n",
    "Use the following code:\n",
    "```\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "X = cancer_data.data\n",
    "y = cancer_data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gARuVdde8Gry",
   "metadata": {
    "id": "gARuVdde8Gry"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "X = cancer_data.data\n",
    "y = cancer_data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52038923",
   "metadata": {
    "id": "52038923"
   },
   "source": [
    "Q6: Tune the hyperparameters of an elastic net model using 3-fold cross-validation. Use `GridSearchCV` from `sklearn`. What set of hyperparameters did you pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "jzG-W9VL8fDW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1708808870097,
     "user": {
      "displayName": "Nidhi Gaonkar",
      "userId": "11008239071912295987"
     },
     "user_tz": 480
    },
    "id": "jzG-W9VL8fDW",
    "outputId": "777963e6-17d2-4253-ce70-b9982a9755ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.0001, 0.001, 0.01, 0.1, 1, 10], 'l1_ratio': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])}\n",
      "Best Hyperparameters: {'C': 0.001, 'l1_ratio': 0.6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "elastic_net = LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", max_iter=10000)\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'C': [1e-4, 0.001, 0.01, 0.1, 1, 10],  # Values for alpha\n",
    "    'l1_ratio': np.arange(0.1,1.1,0.1),  # Values for l1_ratio\n",
    "}\n",
    "\n",
    "print(param_grid)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "elastic_net_grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "elastic_net_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", elastic_net_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216d034",
   "metadata": {},
   "source": [
    "Q7: What is the AUC of the elastic net model with the selected hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4965ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978391356542617"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "test_auc = roc_auc_score(\n",
    "    y_test,\n",
    "    elastic_net_grid_search.predict_proba(X_test)[:,1]\n",
    ")\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5cf68",
   "metadata": {},
   "source": [
    "Q8: Create 95\\% confidence intervals for the AUC using the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c6fa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9641894970601177, 0.9947312284491894)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_test = y_test.size\n",
    "boot_aucs = []\n",
    "for b in range(100):\n",
    "    rand_idxs = np.random.choice(n_test, n_test, replace=True)\n",
    "    boot_auc = roc_auc_score(\n",
    "        y_test[rand_idxs],\n",
    "        elastic_net_grid_search.predict_proba(X_test[rand_idxs])[:,1]\n",
    "    )\n",
    "    boot_aucs.append(boot_auc)\n",
    "\n",
    "diff_quantiles = np.quantile(test_auc - np.array(boot_aucs), q=[0.025,0.975])\n",
    "(test_auc + diff_quantiles[0], test_auc + diff_quantiles[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}